{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mountainsImageGeneratorGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE74IvOaMzPr"
      },
      "source": [
        "#!pip install tensorflow-gpu\n",
        "#Without this, GPU memory no longer caps at 0.1 GB (not utilized; CPU used). The default tensorflow gpu installation on colab machines is correct."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu2wFGXcPHnS",
        "outputId": "b66a5ab4-0604-4cba-c4a5-2c19b037374e"
      },
      "source": [
        "!pip install git+https://github.com/Joeclinton1/google-images-download.git"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Joeclinton1/google-images-download.git\n",
            "  Cloning https://github.com/Joeclinton1/google-images-download.git to /tmp/pip-req-build-ld368s_x\n",
            "  Running command git clone -q https://github.com/Joeclinton1/google-images-download.git /tmp/pip-req-build-ld368s_x\n",
            "Requirement already satisfied (use --upgrade to upgrade): google-images-download==2.8.0 from git+https://github.com/Joeclinton1/google-images-download.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (from google-images-download==2.8.0) (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium->google-images-download==2.8.0) (1.24.3)\n",
            "Building wheels for collected packages: google-images-download\n",
            "  Building wheel for google-images-download (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-images-download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=15833 sha256=a37341afc87ffbce2a219dfbdabdddb9a16da7030b9a79dc9c51af9a82281bef\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-polvz6qb/wheels/1a/36/c9/53bd827bc241b69fe47b90731625459627f82694ecd8a88273\n",
            "Successfully built google-images-download\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T7qizkGa9Fy"
      },
      "source": [
        "from zipfile import ZipFile"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2BLGczDbWyq"
      },
      "source": [
        "with ZipFile(\"resizedImages.zip\",'r') as zip1:\n",
        "  zip1.extractall()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bprWmtaNOFSj",
        "outputId": "7f9f6332-f5b7-4557-9d4f-de034fccfdeb"
      },
      "source": [
        "\"\"\"\n",
        "Created on Wed May  5 21:12:02 2021\n",
        "\n",
        "@author: Rajat Bakshi\n",
        "\"\"\"\n",
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
        "import json\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from PIL import Image, ImageOps\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
        "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os \n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google_images_download import google_images_download\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        "\n",
        "\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 652317148362666000\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 8431595303887800435\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 1327649695300519500\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 7250706432\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 1247899391922059433\n",
            "physical_device_desc: \"device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\"\n",
            "]\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPk-0KtFb_hR"
      },
      "source": [
        "The following block of code downloads images using google images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wpA-AHFcHtL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "f283c082-f504-4d98-ca83-558e56f3c430"
      },
      "source": [
        "'''\n",
        "\n",
        "response=google_images_download.googleimagesdownload()\n",
        "arguments={\"keywords\":\"snowy mountains\", \"limit\": 100, \"print_urls\": False}\n",
        "response.download(arguments)\n",
        "\n",
        "arguments={\"keywords\":\"desert mountains\", \"limit\": 100, \"print_urls\": False}\n",
        "response.download(arguments)\n",
        "\n",
        "arguments={\"keywords\":\"green mountains\", \"limit\": 100, \"print_urls\": False}\n",
        "response.download(arguments)\n",
        "\n",
        "arguments={\"keywords\":\"high rocky mountains\", \"limit\": 100, \"print_urls\": False}\n",
        "response.download(arguments)\n",
        "\n",
        "arguments={\"keywords\":\"high mountains\", \"limit\": 100, \"print_urls\": False}\n",
        "response.download(arguments)\n",
        "\n",
        "arguments={\"keywords\":\"scottish highland mountains\", \"limit\": 100, \"print_urls\": False}\n",
        "response.download(arguments)\n",
        "\n",
        "\n",
        "\n",
        "def get_all_images(folder, ext):\n",
        "\n",
        "    all_files = []\n",
        "    #Iterate through all files in folder\n",
        "    for file in os.listdir(folder):\n",
        "        #Get the file extension\n",
        "        _,  file_ext = os.path.splitext(file)\n",
        "        \n",
        "        #If file is of given extension, get it's full path and append to list\n",
        "        if ext in file_ext:\n",
        "            full_file_path = os.path.join(folder, file)\n",
        "            all_files.append(full_file_path)\n",
        "\n",
        "    #Get list of all files\n",
        "    return all_files\n",
        "\n",
        "imagePaths1 = get_all_images('D:\\MountainsGeneratorGAN\\downloads\\desertMountains', 'jpg')\n",
        "imagePaths2 = get_all_images('D:\\MountainsGeneratorGAN\\downloads\\greenMountains', 'jpg')\n",
        "imagePaths3 = get_all_images('D:\\MountainsGeneratorGAN\\downloads\\highMountains', 'jpg')\n",
        "imagePaths4 = get_all_images('D:\\MountainsGeneratorGAN\\downloads\\highRockyMountains', 'jpg')\n",
        "imagePaths5 = get_all_images('D:\\MountainsGeneratorGAN\\downloads\\scottishHighlandMountains', 'jpg')\n",
        "imagePaths6 = get_all_images('D:\\MountainsGeneratorGAN\\downloads\\snowyMountains', 'jpg')\n",
        "\n",
        "imagePaths=[]\n",
        "imagePaths.extend(imagePaths1)\n",
        "imagePaths.extend(imagePaths2)\n",
        "imagePaths.extend(imagePaths3)\n",
        "imagePaths.extend(imagePaths4)\n",
        "imagePaths.extend(imagePaths5)\n",
        "imagePaths.extend(imagePaths6)\n",
        "\n",
        "if not os.path.exists('resizedImages'):\n",
        "    os.makedirs('resizedImages')\n",
        "    \n",
        "imageCount=0\n",
        "for imagePath in imagePaths:\n",
        "    imageCount+=1\n",
        "    image = Image.open(imagePath)\n",
        "    image.thumbnail((200, 200))\n",
        "    image.save('resizedImages/mtnImage'+str(imageCount)+'.jpg')\n",
        "    mirroredImage=ImageOps.mirror(image)\n",
        "    mirroredImage.save('resizedImages/mtnImage'+str(imageCount)+'mirrored.jpg')\n",
        "\n",
        "'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nresponse=google_images_download.googleimagesdownload()\\narguments={\"keywords\":\"snowy mountains\", \"limit\": 100, \"print_urls\": False}\\nresponse.download(arguments)\\n\\narguments={\"keywords\":\"desert mountains\", \"limit\": 100, \"print_urls\": False}\\nresponse.download(arguments)\\n\\narguments={\"keywords\":\"green mountains\", \"limit\": 100, \"print_urls\": False}\\nresponse.download(arguments)\\n\\narguments={\"keywords\":\"high rocky mountains\", \"limit\": 100, \"print_urls\": False}\\nresponse.download(arguments)\\n\\narguments={\"keywords\":\"high mountains\", \"limit\": 100, \"print_urls\": False}\\nresponse.download(arguments)\\n\\narguments={\"keywords\":\"scottish highland mountains\", \"limit\": 100, \"print_urls\": False}\\nresponse.download(arguments)\\n\\n\\n\\ndef get_all_images(folder, ext):\\n\\n    all_files = []\\n    #Iterate through all files in folder\\n    for file in os.listdir(folder):\\n        #Get the file extension\\n        _,  file_ext = os.path.splitext(file)\\n        \\n        #If file is of given extension, get it\\'s full path and append to list\\n        if ext in file_ext:\\n            full_file_path = os.path.join(folder, file)\\n            all_files.append(full_file_path)\\n\\n    #Get list of all files\\n    return all_files\\n\\nimagePaths1 = get_all_images(\\'D:\\\\MountainsGeneratorGAN\\\\downloads\\\\desertMountains\\', \\'jpg\\')\\nimagePaths2 = get_all_images(\\'D:\\\\MountainsGeneratorGAN\\\\downloads\\\\greenMountains\\', \\'jpg\\')\\nimagePaths3 = get_all_images(\\'D:\\\\MountainsGeneratorGAN\\\\downloads\\\\highMountains\\', \\'jpg\\')\\nimagePaths4 = get_all_images(\\'D:\\\\MountainsGeneratorGAN\\\\downloads\\\\highRockyMountains\\', \\'jpg\\')\\nimagePaths5 = get_all_images(\\'D:\\\\MountainsGeneratorGAN\\\\downloads\\\\scottishHighlandMountains\\', \\'jpg\\')\\nimagePaths6 = get_all_images(\\'D:\\\\MountainsGeneratorGAN\\\\downloads\\\\snowyMountains\\', \\'jpg\\')\\n\\nimagePaths=[]\\nimagePaths.extend(imagePaths1)\\nimagePaths.extend(imagePaths2)\\nimagePaths.extend(imagePaths3)\\nimagePaths.extend(imagePaths4)\\nimagePaths.extend(imagePaths5)\\nimagePaths.extend(imagePaths6)\\n\\nif not os.path.exists(\\'resizedImages\\'):\\n    os.makedirs(\\'resizedImages\\')\\n    \\nimageCount=0\\nfor imagePath in imagePaths:\\n    imageCount+=1\\n    image = Image.open(imagePath)\\n    image.thumbnail((200, 200))\\n    image.save(\\'resizedImages/mtnImage\\'+str(imageCount)+\\'.jpg\\')\\n    mirroredImage=ImageOps.mirror(image)\\n    mirroredImage.save(\\'resizedImages/mtnImage\\'+str(imageCount)+\\'mirrored.jpg\\')\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZcTJ7PUcW97"
      },
      "source": [
        "keras.backend.clear_session() #clearing VRAM"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9EIMKPQcnzE"
      },
      "source": [
        "The below block of code contains training parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AErien9lch2S"
      },
      "source": [
        "DATA_PATH='resizedImages'\n",
        "\n",
        "GENERATE_RES = 5 # Generation resolution factor \n",
        "# (1=32, 2=64, 3=96, 4=128, etc.)\n",
        "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
        "IMAGE_CHANNELS = 3\n",
        "\n",
        "PREVIEW_ROWS = 7\n",
        "PREVIEW_COLS = 7\n",
        "PREVIEW_MARGIN = 16\n",
        "\n",
        "# Size vector to generate images from\n",
        "SEED_SIZE = 1000\n",
        "EPOCHS = 4000\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 958"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gGazQjLc2bG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52c758a-a0bd-4220-ebd5-043ba65b18f2"
      },
      "source": [
        "training_binary_path = os.path.join(DATA_PATH,\n",
        "        f'training_data_{GENERATE_SQUARE}_{GENERATE_SQUARE}.npy')\n",
        "\n",
        "print(f\"Looking for file: {training_binary_path}\")\n",
        "\n",
        "if not os.path.isfile(training_binary_path):\n",
        "    print(\"Loading training images...\")\n",
        "    \n",
        "    training_data = []\n",
        "    for filename in tqdm(os.listdir(DATA_PATH)):\n",
        "        path = os.path.join(DATA_PATH,filename)\n",
        "        if os.path.isfile(path):\n",
        "          image = Image.open(path).resize((GENERATE_SQUARE,\n",
        "                GENERATE_SQUARE),Image.ANTIALIAS)\n",
        "          training_data.append(np.asarray(image))\n",
        "    \n",
        "    training_data = np.reshape(training_data,(-1,GENERATE_SQUARE,\n",
        "              GENERATE_SQUARE,IMAGE_CHANNELS))\n",
        "    training_data = training_data.astype(np.float32)\n",
        "    training_data = training_data / 127.5 - 1.\n",
        "\n",
        "    print(\"Saving training image binary...\")\n",
        "    np.save(training_binary_path,training_data)\n",
        "\n",
        "\n",
        "else:\n",
        "  print(\"Loading previous training pickle...\")\n",
        "  training_data = np.load(training_binary_path)\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(training_data) \\\n",
        "    .shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  7%|▋         | 69/960 [00:00<00:01, 684.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Looking for file: resizedImages/training_data_160_160.npy\n",
            "Loading training images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 960/960 [00:01<00:00, 712.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving training image binary...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2d9sq1vdRTj"
      },
      "source": [
        "Generator and Discriminator models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RieUkve3dUpT"
      },
      "source": [
        "def build_generator(seed_size, channels):\n",
        "    \n",
        "    model=Sequential()\n",
        "    \n",
        "    model.add(Dense(4*4*256,activation=\"relu\",input_dim=seed_size))\n",
        "    model.add(Reshape((4,4,256)))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "   \n",
        "    # Output resolution, additional upsampling\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    if GENERATE_RES>1:\n",
        "      model.add(UpSampling2D(size=(GENERATE_RES,GENERATE_RES)))\n",
        "      model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
        "      model.add(BatchNormalization(momentum=0.8))\n",
        "      model.add(Activation(\"relu\"))\n",
        "\n",
        "    # Final CNN layer\n",
        "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_discriminator(image_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, \n",
        "                     padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PHCiLW5dX0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24895560-c9fb-4df9-ba33-543ab7c774b0"
      },
      "source": [
        "def save_images(cnt,noise):\n",
        "  image_array = np.full(( \n",
        "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
        "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), 3), \n",
        "      255, dtype=np.uint8)\n",
        "  \n",
        "  generated_images = generator.predict(noise)\n",
        "\n",
        "  generated_images = 0.5 * generated_images + 0.5\n",
        "\n",
        "  image_count = 0\n",
        "  for row in range(PREVIEW_ROWS):\n",
        "      for col in range(PREVIEW_COLS):\n",
        "        r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "        c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
        "        image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] \\\n",
        "            = generated_images[image_count] * 255\n",
        "        image_count += 1\n",
        "\n",
        "          \n",
        "  output_path = os.path.join(DATA_PATH,'output')\n",
        "  if not os.path.exists(output_path):\n",
        "      os.makedirs(output_path)\n",
        "  \n",
        "  filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
        "  im = Image.fromarray(image_array)\n",
        "  im.save(filename)\n",
        "\n",
        "\n",
        "generator = build_generator(SEED_SIZE, IMAGE_CHANNELS)\n",
        "\n",
        "noise = tf.random.normal([1, SEED_SIZE])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0])\n",
        "\n",
        "image_shape = (GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS)\n",
        "\n",
        "discriminator = build_discriminator(image_shape)\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)\n",
        "\n",
        "\n",
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(7e-5,0) #learning rate, momentum\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(10e-5,0)\n",
        "\n",
        "\n",
        "\n",
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "    generated_images = generator(seed, training=True)\n",
        "    \n",
        "            \n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "        \n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "    \n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(\\\n",
        "        gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(\\\n",
        "        disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(\n",
        "        gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(\n",
        "        gradients_of_discriminator, \n",
        "        discriminator.trainable_variables))\n",
        "  return gen_loss,disc_loss\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, \n",
        "                                       SEED_SIZE))\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    gen_loss_list = []\n",
        "    disc_loss_list = []\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      t = train_step(image_batch)\n",
        "      gen_loss_list.append(t[0])\n",
        "      disc_loss_list.append(t[1])\n",
        "\n",
        "    g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
        "    d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
        "\n",
        "    epoch_elapsed = time.time()-epoch_start\n",
        "    print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss},'\\\n",
        "           ' {hms_string(epoch_elapsed)}')\n",
        "    save_images(epoch,fixed_seed)\n",
        "    \n",
        "    \n",
        "train(train_dataset, EPOCHS)\n",
        "\n",
        "generator.save(os.path.join(DATA_PATH,\"landscape_generator.h5\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.5017804]], shape=(1, 1), dtype=float32)\n",
            "Epoch 1, gen loss=2.949155569076538,disc loss=2.419538974761963, {hms_string(epoch_elapsed)}\n",
            "Epoch 2, gen loss=3.6130549907684326,disc loss=1.864182949066162, {hms_string(epoch_elapsed)}\n",
            "Epoch 3, gen loss=3.438223123550415,disc loss=2.545619249343872, {hms_string(epoch_elapsed)}\n",
            "Epoch 4, gen loss=3.643547773361206,disc loss=2.642657995223999, {hms_string(epoch_elapsed)}\n",
            "Epoch 5, gen loss=3.4602606296539307,disc loss=2.8057703971862793, {hms_string(epoch_elapsed)}\n",
            "Epoch 6, gen loss=3.1209981441497803,disc loss=3.1440160274505615, {hms_string(epoch_elapsed)}\n",
            "Epoch 7, gen loss=3.1248440742492676,disc loss=2.624812364578247, {hms_string(epoch_elapsed)}\n",
            "Epoch 8, gen loss=3.067058563232422,disc loss=2.763556480407715, {hms_string(epoch_elapsed)}\n",
            "Epoch 9, gen loss=3.0184173583984375,disc loss=2.4004366397857666, {hms_string(epoch_elapsed)}\n",
            "Epoch 10, gen loss=3.145270824432373,disc loss=2.2853779792785645, {hms_string(epoch_elapsed)}\n",
            "Epoch 11, gen loss=3.2167088985443115,disc loss=2.010532855987549, {hms_string(epoch_elapsed)}\n",
            "Epoch 12, gen loss=3.395202875137329,disc loss=1.8868584632873535, {hms_string(epoch_elapsed)}\n",
            "Epoch 13, gen loss=3.4225118160247803,disc loss=2.388314723968506, {hms_string(epoch_elapsed)}\n",
            "Epoch 14, gen loss=3.4968175888061523,disc loss=2.3225393295288086, {hms_string(epoch_elapsed)}\n",
            "Epoch 15, gen loss=3.2230684757232666,disc loss=2.60073184967041, {hms_string(epoch_elapsed)}\n",
            "Epoch 16, gen loss=3.0440547466278076,disc loss=2.9852139949798584, {hms_string(epoch_elapsed)}\n",
            "Epoch 17, gen loss=2.829681396484375,disc loss=2.6007134914398193, {hms_string(epoch_elapsed)}\n",
            "Epoch 18, gen loss=2.8923819065093994,disc loss=2.172786235809326, {hms_string(epoch_elapsed)}\n",
            "Epoch 19, gen loss=3.1170668601989746,disc loss=2.531250476837158, {hms_string(epoch_elapsed)}\n",
            "Epoch 20, gen loss=2.7728517055511475,disc loss=2.136650323867798, {hms_string(epoch_elapsed)}\n",
            "Epoch 21, gen loss=2.575491428375244,disc loss=1.991056203842163, {hms_string(epoch_elapsed)}\n",
            "Epoch 22, gen loss=2.570713520050049,disc loss=2.4051010608673096, {hms_string(epoch_elapsed)}\n",
            "Epoch 23, gen loss=2.373835563659668,disc loss=2.3271608352661133, {hms_string(epoch_elapsed)}\n",
            "Epoch 24, gen loss=2.4903407096862793,disc loss=2.6817665100097656, {hms_string(epoch_elapsed)}\n",
            "Epoch 25, gen loss=2.4292261600494385,disc loss=2.4254355430603027, {hms_string(epoch_elapsed)}\n",
            "Epoch 26, gen loss=2.4737374782562256,disc loss=1.9964525699615479, {hms_string(epoch_elapsed)}\n",
            "Epoch 27, gen loss=2.4674086570739746,disc loss=2.014212131500244, {hms_string(epoch_elapsed)}\n",
            "Epoch 28, gen loss=2.4683480262756348,disc loss=1.9146593809127808, {hms_string(epoch_elapsed)}\n",
            "Epoch 29, gen loss=2.581109046936035,disc loss=1.848320722579956, {hms_string(epoch_elapsed)}\n",
            "Epoch 30, gen loss=2.5133614540100098,disc loss=1.7581828832626343, {hms_string(epoch_elapsed)}\n",
            "Epoch 31, gen loss=2.3987886905670166,disc loss=1.7431671619415283, {hms_string(epoch_elapsed)}\n",
            "Epoch 32, gen loss=2.6713709831237793,disc loss=1.702579379081726, {hms_string(epoch_elapsed)}\n",
            "Epoch 33, gen loss=2.565568447113037,disc loss=1.5700910091400146, {hms_string(epoch_elapsed)}\n",
            "Epoch 34, gen loss=2.456557273864746,disc loss=1.4507472515106201, {hms_string(epoch_elapsed)}\n",
            "Epoch 35, gen loss=2.6656999588012695,disc loss=1.5242563486099243, {hms_string(epoch_elapsed)}\n",
            "Epoch 36, gen loss=2.567223310470581,disc loss=1.4566892385482788, {hms_string(epoch_elapsed)}\n",
            "Epoch 37, gen loss=2.5795791149139404,disc loss=1.0881505012512207, {hms_string(epoch_elapsed)}\n",
            "Epoch 38, gen loss=2.791997194290161,disc loss=1.2987170219421387, {hms_string(epoch_elapsed)}\n",
            "Epoch 39, gen loss=2.70570707321167,disc loss=1.0273890495300293, {hms_string(epoch_elapsed)}\n",
            "Epoch 40, gen loss=2.659520387649536,disc loss=1.0831146240234375, {hms_string(epoch_elapsed)}\n",
            "Epoch 41, gen loss=2.774303436279297,disc loss=1.109517216682434, {hms_string(epoch_elapsed)}\n",
            "Epoch 42, gen loss=2.513164758682251,disc loss=0.6430760622024536, {hms_string(epoch_elapsed)}\n",
            "Epoch 43, gen loss=2.8879191875457764,disc loss=1.3726283311843872, {hms_string(epoch_elapsed)}\n",
            "Epoch 44, gen loss=3.058458089828491,disc loss=1.0843907594680786, {hms_string(epoch_elapsed)}\n",
            "Epoch 45, gen loss=2.5704360008239746,disc loss=0.7293218970298767, {hms_string(epoch_elapsed)}\n",
            "Epoch 46, gen loss=3.154477834701538,disc loss=1.0728421211242676, {hms_string(epoch_elapsed)}\n",
            "Epoch 47, gen loss=3.166771173477173,disc loss=1.1501601934432983, {hms_string(epoch_elapsed)}\n",
            "Epoch 48, gen loss=2.7568464279174805,disc loss=0.6967852115631104, {hms_string(epoch_elapsed)}\n",
            "Epoch 49, gen loss=2.8261702060699463,disc loss=0.7042123079299927, {hms_string(epoch_elapsed)}\n",
            "Epoch 50, gen loss=3.595522165298462,disc loss=1.404044270515442, {hms_string(epoch_elapsed)}\n",
            "Epoch 51, gen loss=3.5027382373809814,disc loss=1.2050716876983643, {hms_string(epoch_elapsed)}\n",
            "Epoch 52, gen loss=3.1031832695007324,disc loss=0.5589481592178345, {hms_string(epoch_elapsed)}\n",
            "Epoch 53, gen loss=3.127178430557251,disc loss=0.6912828683853149, {hms_string(epoch_elapsed)}\n",
            "Epoch 54, gen loss=3.7969107627868652,disc loss=1.0857689380645752, {hms_string(epoch_elapsed)}\n",
            "Epoch 55, gen loss=3.2701523303985596,disc loss=0.7565733790397644, {hms_string(epoch_elapsed)}\n",
            "Epoch 56, gen loss=3.576575756072998,disc loss=0.8993685245513916, {hms_string(epoch_elapsed)}\n",
            "Epoch 57, gen loss=3.743058681488037,disc loss=1.3038074970245361, {hms_string(epoch_elapsed)}\n",
            "Epoch 58, gen loss=3.663795232772827,disc loss=0.4408809244632721, {hms_string(epoch_elapsed)}\n",
            "Epoch 59, gen loss=3.750842571258545,disc loss=0.526879608631134, {hms_string(epoch_elapsed)}\n",
            "Epoch 60, gen loss=4.4145073890686035,disc loss=1.0793367624282837, {hms_string(epoch_elapsed)}\n",
            "Epoch 61, gen loss=4.248075008392334,disc loss=0.8777675032615662, {hms_string(epoch_elapsed)}\n",
            "Epoch 62, gen loss=4.631535530090332,disc loss=0.25067415833473206, {hms_string(epoch_elapsed)}\n",
            "Epoch 63, gen loss=4.375688076019287,disc loss=0.18357481062412262, {hms_string(epoch_elapsed)}\n",
            "Epoch 64, gen loss=5.640791416168213,disc loss=1.246029019355774, {hms_string(epoch_elapsed)}\n",
            "Epoch 65, gen loss=4.475004196166992,disc loss=0.15258577466011047, {hms_string(epoch_elapsed)}\n",
            "Epoch 66, gen loss=5.0239057540893555,disc loss=0.7956784963607788, {hms_string(epoch_elapsed)}\n",
            "Epoch 67, gen loss=4.538014888763428,disc loss=0.21390004456043243, {hms_string(epoch_elapsed)}\n",
            "Epoch 68, gen loss=4.958505153656006,disc loss=0.13299591839313507, {hms_string(epoch_elapsed)}\n",
            "Epoch 69, gen loss=4.915927410125732,disc loss=0.11796379834413528, {hms_string(epoch_elapsed)}\n",
            "Epoch 70, gen loss=5.410960674285889,disc loss=0.9627045392990112, {hms_string(epoch_elapsed)}\n",
            "Epoch 71, gen loss=4.441370487213135,disc loss=0.22322425246238708, {hms_string(epoch_elapsed)}\n",
            "Epoch 72, gen loss=6.026430130004883,disc loss=2.2271957397460938, {hms_string(epoch_elapsed)}\n",
            "Epoch 73, gen loss=5.114914894104004,disc loss=1.7018890380859375, {hms_string(epoch_elapsed)}\n",
            "Epoch 74, gen loss=4.624797344207764,disc loss=1.339949131011963, {hms_string(epoch_elapsed)}\n",
            "Epoch 75, gen loss=4.567543029785156,disc loss=1.6925196647644043, {hms_string(epoch_elapsed)}\n",
            "Epoch 76, gen loss=4.008950710296631,disc loss=0.746773898601532, {hms_string(epoch_elapsed)}\n",
            "Epoch 77, gen loss=4.058403491973877,disc loss=1.0642212629318237, {hms_string(epoch_elapsed)}\n",
            "Epoch 78, gen loss=4.370728492736816,disc loss=0.9133685827255249, {hms_string(epoch_elapsed)}\n",
            "Epoch 79, gen loss=3.7472047805786133,disc loss=0.5738137364387512, {hms_string(epoch_elapsed)}\n",
            "Epoch 80, gen loss=4.627777099609375,disc loss=1.4352515935897827, {hms_string(epoch_elapsed)}\n",
            "Epoch 81, gen loss=4.3212151527404785,disc loss=1.0035361051559448, {hms_string(epoch_elapsed)}\n",
            "Epoch 82, gen loss=4.097836017608643,disc loss=0.6120172739028931, {hms_string(epoch_elapsed)}\n",
            "Epoch 83, gen loss=4.407471656799316,disc loss=0.7495948672294617, {hms_string(epoch_elapsed)}\n",
            "Epoch 84, gen loss=4.482038497924805,disc loss=0.9797801971435547, {hms_string(epoch_elapsed)}\n",
            "Epoch 85, gen loss=4.15764045715332,disc loss=0.7187643051147461, {hms_string(epoch_elapsed)}\n",
            "Epoch 86, gen loss=4.930549144744873,disc loss=1.1149057149887085, {hms_string(epoch_elapsed)}\n",
            "Epoch 87, gen loss=4.178101062774658,disc loss=0.44469207525253296, {hms_string(epoch_elapsed)}\n",
            "Epoch 88, gen loss=4.1625142097473145,disc loss=0.3995019793510437, {hms_string(epoch_elapsed)}\n",
            "Epoch 89, gen loss=4.513712406158447,disc loss=0.8382975459098816, {hms_string(epoch_elapsed)}\n",
            "Epoch 90, gen loss=5.037265300750732,disc loss=0.7104498744010925, {hms_string(epoch_elapsed)}\n",
            "Epoch 91, gen loss=4.468946933746338,disc loss=0.27162083983421326, {hms_string(epoch_elapsed)}\n",
            "Epoch 92, gen loss=4.230513572692871,disc loss=0.41703715920448303, {hms_string(epoch_elapsed)}\n",
            "Epoch 93, gen loss=4.8426833152771,disc loss=1.1564041376113892, {hms_string(epoch_elapsed)}\n",
            "Epoch 94, gen loss=4.884714126586914,disc loss=0.8354003429412842, {hms_string(epoch_elapsed)}\n",
            "Epoch 95, gen loss=4.684350967407227,disc loss=0.6707392930984497, {hms_string(epoch_elapsed)}\n",
            "Epoch 96, gen loss=4.868134498596191,disc loss=0.5904470682144165, {hms_string(epoch_elapsed)}\n",
            "Epoch 97, gen loss=5.3289384841918945,disc loss=1.2644931077957153, {hms_string(epoch_elapsed)}\n",
            "Epoch 98, gen loss=4.4343109130859375,disc loss=0.7464117407798767, {hms_string(epoch_elapsed)}\n",
            "Epoch 99, gen loss=5.090701580047607,disc loss=0.7019743323326111, {hms_string(epoch_elapsed)}\n",
            "Epoch 100, gen loss=4.858139514923096,disc loss=0.7669591903686523, {hms_string(epoch_elapsed)}\n",
            "Epoch 101, gen loss=5.297492504119873,disc loss=1.1429013013839722, {hms_string(epoch_elapsed)}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}